{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Crawl_books.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"R5bHvSu8cr48"},"source":["import requests\n","import datetime\n","import pandas as pd \n","import numpy as np\n","#from requests_html import HTML\n","#from requests_html import HTMLSession\n","from bs4 import BeautifulSoup\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3PPsTzb9S8Hg"},"source":["## Lấy danh sách các link "]},{"cell_type":"code","metadata":{"id":"qjO0s-nNc5kx"},"source":["arr_data = []\n","for page in range(1, 2):\n","  link =\"https://www.goodreads.com/list/show/7.Best_Books_of_the_21st_Century?page=\"+ str(page)\n","  page = requests.get(link)\n","  soup = BeautifulSoup(page.content, 'html.parser')\n","  arr_link = soup.find_all(\"a\",class_='bookTitle')\n","  for i in range(len(arr_link)):\n","    link =\"https://www.goodreads.com\" + arr_link[i]['href']\n","    arr_data.append(link)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrsVP5Lvc5e3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635838779787,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nam Trần Nhật","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16535636196089484959"}},"outputId":"207bb017-94fb-43a3-a238-93604ac5704c"},"source":["print(\"Tổng số link: \" + str(len(arr_data)))\n","df_link=pd.DataFrame(arr_data)\n","links = df_link[0].values"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tổng số link: 100\n"]}]},{"cell_type":"markdown","metadata":{"id":"S6xtSVY_TBWu"},"source":["## Xử lý từng link sách"]},{"cell_type":"code","metadata":{"id":"RrsQZTx4T5iA"},"source":["arr_data = []\n","for i in range(10):\n","  link = links[i]\n","  page = requests.get(link)\n","  soup = BeautifulSoup(page.content, 'html.parser')\n","  if soup:\n","    id = link.split('show/')[-1].split('-')[0].split('.')[0]\n","    title = soup.find(id='bookTitle')\n","    serie  = float('nan')\n","    author  = float('nan')\n","    author_link  = float('nan')\n","    rating_count  = float('nan')\n","    review_count  = float('nan')\n","    number_of_pages  = float('nan')\n","    date_published  = float('nan')\n","    publisher  = float('nan')\n","    original_title  = float('nan')\n","    genre_and_votes  = float('nan')\n","    isbn  = float('nan')\n","    isbn13  = float('nan')\n","    setting  = float('nan')\n","    characters  = float('nan')\n","    description = float('nan')\n","    awards = float('nan')\n","    rating = float('nan')\n","    rating = soup.find(itemprop = 'ratingValue').text.strip()\n","    serie = soup.find(id='bookSeries')#\n","    if serie:\n","      serie = serie.text.strip()\n","    author_section = soup.find(id='bookAuthors')\n","    if author_section:\n","      author_section = author_section.find(class_='authorName')\n","    if author_section:\n","      author = author_section.text.strip()\n","      author_link = author_section['href'] #\n","    title = soup.find(id='bookTitle')\n","    if title:\n","      title = title.text.strip()\n","    review_section = soup.find(id='reviewControls')\n","    if review_section:\n","      review_section = review_section.find(class_='reviewControls--left greyText')\n","    if review_section:\n","      temp = re.findall(r'[\\w,]+', review_section.text)\n","      rating_count = float(temp[0].replace(',', '')) #\n","      review_count = float(temp[2].replace(',', '')) #\n","    if soup.find(itemprop='numberOfPages'):\n","      number_of_pages = int(soup.find(itemprop='numberOfPages').text.split(' ')[0].strip()) #\n","    temp = soup.find(id='details')\n","    if temp:\n","      #print(temp)\n","      temp = temp.find_all(class_='row')\n","      if len(temp) > 1:\n","        temp = temp[1]\n","        date_published = temp.text.strip().split('\\n')[1].strip()\n","        if len(temp.text.strip().split('\\n')) > 2:\n","          #print(temp.text.strip().split('\\n'))\n","          publisher = temp.text.strip().split('\\n')[2].split('by')\n","          if len(publisher) >= 2:\n","            publisher = publisher[1].strip()\n","    a = soup.find(id='bookDataBox')\n","    if a:\n","      a = a.find_all(class_='infoBoxRowTitle')\n","    b = soup.find(id='bookDataBox')\n","    if b:\n","      b = b.find_all(class_='infoBoxRowItem')\n","    if a and b:\n","      for i in range(len(a)):\n","        if a[i].text.strip() == 'Original Title':\n","          original_title = b[i].text.strip()\n","        if a[i].text.strip() == 'ISBN':\n","          isbn = b[i].text.strip()\n","        if a[i].text.strip() == 'Characters':\n","          characters = b[i].text.strip()\n","        if a[i].text.strip() == 'Setting':\n","          setting = b[i].text.strip()\n","        if a[i].text.strip() == 'Literary Awards':\n","          awards = b[i].text.strip()\n","      if isbn == isbn:\n","        temp = re.findall(r'[\\w]+', isbn)\n","        if (len(temp) == 3):\n","          isbn = temp[0]\n","          isbn13 = temp[2]\n","    genre_and_votes_arr = []\n","    temp = soup.find_all(class_='elementList ')\n","    for i in temp:\n","      left = i.find(class_='left').find_all(class_='actionLinkLite bookPageGenreLink')\n","      left_arr = []\n","      for j in left:\n","        left_arr.append(j.text.strip())\n","        left_text = '-'.join(left_arr)\n","        right_text = i.find(class_='right').text.split(' ')[12].strip().replace(',', '')\n","      genre_and_votes_arr.append(str(left_text) + ' ' + str(right_text))\n","    genre_and_votes = ', '.join(genre_and_votes_arr)\n","    description = soup.find(id='description')\n","    if description:\n","      description = description.text.strip()\n","    combine_data = [id,title,link, serie, author, author_link, rating_count,\n","                    review_count, number_of_pages, date_published, publisher, original_title,\n","                    genre_and_votes, isbn, isbn13, setting, characters, description,awards,rating]\n","    arr_data.append(combine_data.copy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIv5AN4oc5Vo"},"source":["feature = ['id','title','link', 'serie', 'author', 'author_link', 'rating_count',\n","                    'eview_count', 'number_of_pages', 'date_published', 'publisher', 'original_title',\n","                    'genre_and_votes', 'isbn', 'isbn13', 'setting', 'characters', 'description','awards','rating']\n","df= pd.DataFrame(arr_data,columns=feature)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFEvjqLnc5Pp","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1635839038323,"user_tz":-420,"elapsed":379,"user":{"displayName":"Nam Trần Nhật","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16535636196089484959"}},"outputId":"ac061938-ad34-4c57-b5ae-ec8a8ed02833"},"source":["df['genre_and_votes'][6]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Fiction 12877, Historical-Historical Fiction 11633, Historical 2275, Adult 1381, Adult Fiction 1242, Contemporary 1005, Classics 920, Audiobook 902, Book Club 826'"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"e7iaDYtnc5MS"},"source":["df.to_csv('Data.csv')"],"execution_count":null,"outputs":[]}]}